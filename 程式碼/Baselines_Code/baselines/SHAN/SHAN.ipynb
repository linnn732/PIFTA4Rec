{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c89370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750a039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generation():\n",
    "    def __init__(self, type):\n",
    "        print('init')\n",
    "        self.data_type = type\n",
    "        self.dataset = './data/' + self.data_type + '.csv'\n",
    "\n",
    "        self.train_users = []\n",
    "        self.train_sessions = []  # 当前的session\n",
    "        self.train_items = []  # 随机采样得到的positive\n",
    "        self.train_neg_items = []  # 随机采样得到的negative\n",
    "        self.train_pre_sessions = []  # 之前的session集合\n",
    "\n",
    "        self.test_users = []\n",
    "        self.test_candidate_items = []\n",
    "        self.test_sessions = []\n",
    "        self.test_pre_sessions = []\n",
    "        self.test_real_items = []\n",
    "\n",
    "        self.neg_number = 5\n",
    "        self.user_number = 0\n",
    "        self.item_number = 0\n",
    "        self.train_batch_id = 0\n",
    "        self.test_batch_id = 0\n",
    "        self.records_number = 0\n",
    "\n",
    "    def gen_train_test_data(self):\n",
    "        self.data = pd.read_csv(self.dataset, names=['user', 'sessions'], dtype='str')\n",
    "        is_first_line = 1\n",
    "        for line in self.data.values:\n",
    "            if is_first_line:\n",
    "                self.user_number = int(line[0])\n",
    "                self.item_number = int(line[1])\n",
    "                print(\"user_number:\",self.user_number)\n",
    "                print(\"item_number:\",self.item_number)\n",
    "                self.user_purchased_item = dict()  # 保存每个用户购买记录，可用于train时负采样和test时剔除已打分商品\n",
    "                is_first_line = 0\n",
    "            else:\n",
    "                user_id = int(line[0])\n",
    "                sessions = [i for i in line[1].split('@')]\n",
    "                size = len(sessions)\n",
    "                the_first_session = [int(i) for i in sessions[0].split(':')]\n",
    "                self.train_pre_sessions.append(the_first_session)\n",
    "                tmp = copy.deepcopy(the_first_session)\n",
    "                self.user_purchased_item[user_id] = tmp # 儲存用戶第一個購物籃項目串列\n",
    "                for j in range(1, size - 1):\n",
    "                    # 每个用户的每个session在train_users中都对应着其user_id\n",
    "                    self.train_users.append(user_id)\n",
    "                    current_session = [int(it) for it in sessions[j].split(':')]\n",
    "                    neg = self.gen_neg(user_id)\n",
    "                    self.train_neg_items.append(neg)\n",
    "                    # 将当前session加入到用户购买的记录当中\n",
    "                    # 之所以放在这个位置，是因为在选择测试item时，需要将session中的一个item移除、\n",
    "                    # 如果放在后面操作，当前session中其实是少了一个用来做当前session进行预测的item\n",
    "                    if j != 1:\n",
    "                        tmp = copy.deepcopy(self.user_purchased_item[user_id])\n",
    "                        self.train_pre_sessions.append(tmp)\n",
    "                    self.user_purchased_item[user_id].extend(current_session)\n",
    "                    # 随机挑选一个作为prediction item\n",
    "                    item = random.choice(current_session)\n",
    "                    self.train_items.append(item)\n",
    "                    current_session.remove(item)\n",
    "                    self.train_sessions.append(current_session)\n",
    "                    self.records_number += 1\n",
    "                    # test_sessions是train_data的最後一個購物籃(短期)\n",
    "                    if j == size-2:\n",
    "                        self.test_sessions.append(current_session)\n",
    "\n",
    "                # 对test的数据集也要格式化，test中每个用户都只有一个current session\n",
    "                # target改成最後一個購物籃，test_sessions是train_data的最後一個購物籃(短期)，test_pre_sessions是train_data的最後一個購物籃之前的所有購物籃(長期)\n",
    "                self.test_users.append(user_id)\n",
    "                current_session = [int(it) for it in sessions[size - 1].split(':')]\n",
    "                self.test_real_items.append(current_session)\n",
    "                self.test_pre_sessions.append(self.user_purchased_item[user_id])\n",
    "        test_zipped = list(zip( self.test_users, self.test_sessions, self.test_pre_sessions, self.test_real_items))\n",
    "        random.shuffle(test_zipped)\n",
    "        self.test_users, self.test_sessions, self.test_pre_sessions, self.test_real_items = zip(*test_zipped)\n",
    "        # test集中每个用户的预测的候选集就是整个item集合\n",
    "        self.test_candidate_items = list(range(self.item_number))\n",
    "\n",
    "        train_zipped = list(zip( self.train_users, self.train_sessions, self.train_pre_sessions, self.train_neg_items, self.train_items))\n",
    "        random.shuffle(train_zipped)\n",
    "        self.train_users, self.train_sessions, self.train_pre_sessions, self.train_neg_items, self.train_items = zip(*train_zipped)\n",
    "\n",
    "    def gen_neg(self, user_id):\n",
    "        neg_item_set = set()\n",
    "        while len(neg_item_set) < self.neg_number:\n",
    "            neg_item = np.random.randint(self.item_number)\n",
    "            while neg_item in self.user_purchased_item[user_id]:\n",
    "                neg_item = np.random.randint(self.item_number)\n",
    "            neg_item_set.add(neg_item)\n",
    "        return list(neg_item_set)\n",
    "\n",
    "    def gen_train_batch_data(self, batch_size):\n",
    "        l = len(self.train_users)\n",
    "\n",
    "        if self.train_batch_id >= l:\n",
    "            self.train_batch_id = 0\n",
    "\n",
    "        batch_user = self.train_users[self.train_batch_id:self.train_batch_id + batch_size]\n",
    "        batch_item = self.train_items[self.train_batch_id:self.train_batch_id + batch_size]\n",
    "        batch_session = self.train_sessions[self.train_batch_id]\n",
    "        if self.neg_number>1:\n",
    "            batch_neg_item = self.train_neg_items[self.train_batch_id:self.train_batch_id + batch_size][0]\n",
    "        else:\n",
    "            batch_neg_item = self.train_neg_items[self.train_batch_id:self.train_batch_id + batch_size]\n",
    "        batch_pre_session = self.train_pre_sessions[self.train_batch_id]\n",
    "\n",
    "        self.train_batch_id = self.train_batch_id + batch_size\n",
    "\n",
    "        return batch_user, batch_item, batch_session, batch_neg_item, batch_pre_session\n",
    "\n",
    "    def gen_test_batch_data(self, user_id, batch_size):\n",
    "\n",
    "        batch_user = self.test_users[user_id:user_id + batch_size]\n",
    "        batch_item = self.test_candidate_items\n",
    "        batch_session = self.test_sessions[user_id]\n",
    "        batch_pre_session = self.test_pre_sessions[user_id]\n",
    "\n",
    "        return batch_user, batch_item, batch_session, batch_pre_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b547e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "class shan():\n",
    "    def __init__(self, data_type, global_dimension, epochs, lr, lamada_u_v, lamada_a, num):\n",
    "        print('init ... ')\n",
    "        self.input_data_type = data_type\n",
    "        \n",
    "        self.dg = data_generation(self.input_data_type)\n",
    "        # 数据格式化\n",
    "        self.dg.gen_train_test_data()\n",
    "\n",
    "        self.train_user_purchased_item_dict = self.dg.user_purchased_item\n",
    "\n",
    "        self.user_number = self.dg.user_number\n",
    "        self.item_number = self.dg.item_number\n",
    "        self.neg_number = self.dg.neg_number\n",
    "\n",
    "        self.test_users = self.dg.test_users\n",
    "        self.test_candidate_items = self.dg.test_candidate_items\n",
    "        self.test_sessions = self.dg.test_sessions\n",
    "        self.test_pre_sessions = self.dg.test_pre_sessions\n",
    "        self.test_real_items = self.dg.test_real_items\n",
    "\n",
    "        self.global_dimension = global_dimension # 論文: 100\n",
    "        self.batch_size = 1\n",
    "        self.K = 10\n",
    "        self.results = []  # 可用来保存test每个用户的预测结果，最终计算precision\n",
    "        self.num = num # 紀錄第幾次實驗用\n",
    "\n",
    "        self.step = 0\n",
    "        self.iteration = epochs\n",
    "        self.lr = 0.05\n",
    "        self.lamada_u_v = lamada_u_v # 論文: [0.01、0.001、0.0001]\n",
    "        self.lamada_a = lamada_a  # 論文: [0,1,10,50]\n",
    "\n",
    "        self.loss = 0\n",
    "        self.path = f'{str(self.num)}_Shan_{self.input_data_type}_d{str(self.global_dimension)}_lr{str(self.lr)}_neg{str(self.neg_number)}_uv{str(self.lamada_u_v)}_a{str(self.lamada_a)}'\n",
    "        \n",
    "        # 日志基本配置\n",
    "#         logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        self.logger = logging.getLogger()\n",
    "#         fh = logging.FileHandler(f'./results/{self.input_data_type}/{self.path}' , mode='a', encoding=None, delay=False)\n",
    "#         self.logger.addHandler(fh)\n",
    "\n",
    "        self.initializer = tf.random_normal_initializer(mean=0, stddev=0.01)\n",
    "        self.initializer_param = tf.random_uniform_initializer(minval=-np.sqrt(3 / self.global_dimension),\n",
    "                                                               maxval=-np.sqrt(3 / self.global_dimension))\n",
    "\n",
    "        self.user_id = tf.compat.v1.placeholder(tf.int32, shape=[None], name='user_id')\n",
    "        self.item_id = tf.compat.v1.placeholder(tf.int32, shape=[None], name='item_id')\n",
    "        # 不管是当前的session，还是之前的session集合，在数据处理阶段都是一个数组，数组内容为item的编号\n",
    "        self.current_session = tf.compat.v1.placeholder(tf.int32, shape=[None], name='current_session')\n",
    "        self.pre_sessions = tf.compat.v1.placeholder(tf.int32, shape=[None], name='pre_sessions')\n",
    "        self.neg_item_id = tf.compat.v1.placeholder(tf.int32, shape=[None], name='neg_item_id')\n",
    "\n",
    "        self.user_embedding_matrix = tf.compat.v1.get_variable('user_embedding_matrix', initializer=self.initializer,\n",
    "                                                     shape=[self.user_number, self.global_dimension])\n",
    "        self.item_embedding_matrix = tf.compat.v1.get_variable('item_embedding_matrix', initializer=self.initializer,\n",
    "                                                     shape=[self.item_number, self.global_dimension])\n",
    "        self.the_first_w = tf.compat.v1.get_variable('the_first_w', initializer=self.initializer_param,\n",
    "                                           shape=[self.global_dimension, self.global_dimension])\n",
    "        self.the_second_w = tf.compat.v1.get_variable('the_second_w', initializer=self.initializer_param,\n",
    "                                            shape=[self.global_dimension, self.global_dimension])\n",
    "        self.the_first_bias = tf.compat.v1.get_variable('the_first_bias', initializer=self.initializer_param,\n",
    "                                              shape=[self.global_dimension])\n",
    "        self.the_second_bias = tf.compat.v1.get_variable('the_second_bias', initializer=self.initializer_param,\n",
    "                                               shape=[self.global_dimension])\n",
    "\n",
    "    def attention_level_one(self, user_embedding, pre_sessions_embedding, the_first_w, the_first_bias):\n",
    "        self.weight = tf.nn.softmax(tf.transpose(tf.matmul(\n",
    "            tf.sigmoid( tf.add(tf.matmul(pre_sessions_embedding, the_first_w), the_first_bias))  # matmul((?,20)(20,20))=(?,20), add=(?,20), \n",
    "            , tf.transpose(user_embedding))))  #  matmul((?,20),(20, ?))=>(?,?)\n",
    "\n",
    "        out = tf.reduce_sum(tf.multiply( pre_sessions_embedding, tf.transpose(self.weight)), axis=0)# (?, 20) (?,?) => (20,)\n",
    "        return out\n",
    "\n",
    "    def attention_level_two(self, long_user_embedding, current_session_embedding, the_second_w, the_second_bias):\n",
    "        # 需要将long_user_embedding加入到current_session_embedding中来进行attention，\n",
    "        # 论文中规定，long_user_embedding的表示也不会根据softmax计算得到的参数而变化。\n",
    "        # self.weight=>(n,1)\n",
    "        self.weight = tf.nn.softmax(tf.transpose(tf.matmul( tf.sigmoid(\n",
    "            tf.add( tf.matmul(tf.concat([current_session_embedding, tf.expand_dims(long_user_embedding, axis=0)], 0), the_second_w), the_second_bias)),  # matmul((?,20)(20,20)), =>shape=(?,20)\n",
    "                tf.transpose(tf.expand_dims(long_user_embedding, axis=0)) ))) #the_second_bias:shape=(20,) ,add(?,20) => matmul((?,20)(20, 1))\n",
    "\n",
    "        out = tf.reduce_sum(\n",
    "            tf.multiply(tf.concat([current_session_embedding, tf.expand_dims(long_user_embedding, axis=0)], 0), tf.transpose(self.weight)), axis=0)\n",
    "        return out\n",
    "\n",
    "    def build_model(self):\n",
    "        print('building model ... ')\n",
    "        self.user_embedding = tf.nn.embedding_lookup(self.user_embedding_matrix, self.user_id)\n",
    "        self.item_embedding = tf.nn.embedding_lookup(self.item_embedding_matrix, self.item_id)\n",
    "        self.current_session_embedding = tf.nn.embedding_lookup(self.item_embedding_matrix, self.current_session)\n",
    "        self.pre_sessions_embedding = tf.nn.embedding_lookup(self.item_embedding_matrix, self.pre_sessions)\n",
    "        self.neg_item_embedding = tf.nn.embedding_lookup(self.item_embedding_matrix, self.neg_item_id)\n",
    "\n",
    "        self.long_user_embedding = self.attention_level_one(self.user_embedding, self.pre_sessions_embedding,\n",
    "                                                            self.the_first_w, self.the_first_bias)\n",
    "        self.hybrid_user_embedding = self.attention_level_two(self.long_user_embedding, self.current_session_embedding,\n",
    "                                                              self.the_second_w, self.the_second_bias)\n",
    "        \n",
    "        # compute preference\n",
    "        self.positive_element_wise = tf.matmul(tf.expand_dims(self.hybrid_user_embedding, axis=0),\n",
    "                                               tf.transpose(self.item_embedding))\n",
    "        self.negative_element_wise = tf.matmul(tf.expand_dims(self.hybrid_user_embedding, axis=0),\n",
    "                                               tf.transpose(self.neg_item_embedding))\n",
    "        \n",
    "        self.intention_loss = tf.reduce_mean(\n",
    "            -tf.math.log(tf.nn.sigmoid(self.positive_element_wise - self.negative_element_wise)))\n",
    "        self.regular_loss_u_v = tf.add(self.lamada_u_v * tf.nn.l2_loss(self.user_embedding),\n",
    "                                       self.lamada_u_v * tf.nn.l2_loss(self.item_embedding))\n",
    "        self.regular_loss_a = tf.add(self.lamada_a * tf.nn.l2_loss(self.the_first_w),\n",
    "                                     self.lamada_a * tf.nn.l2_loss(self.the_second_w))\n",
    "        self.regular_loss = tf.add(self.regular_loss_a, self.regular_loss_u_v)\n",
    "        self.intention_loss = tf.add(self.intention_loss, self.regular_loss)\n",
    "\n",
    "        # 增加test操作，由于每个用户pre_sessions和current_session的长度不一样，\n",
    "        # 所以无法使用同一个矩阵进行表示同时计算，因此每个user计算一次，将结果保留并进行统计\n",
    "        # 注意，test集合的整个item_embeeding得到的是 [M*K]的矩阵，M为所有item的个数，K为维度\n",
    "        self.top_value, self.top_index = tf.nn.top_k(self.positive_element_wise, k=self.K, sorted=True)\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        print('running ... ')\n",
    "        with tf.compat.v1.Session() as self.sess:\n",
    "            self.intention_optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=self.lr).minimize(\n",
    "                self.intention_loss)\n",
    "            init = tf.compat.v1.global_variables_initializer()\n",
    "            self.sess.run(init)\n",
    "\n",
    "            results = []\n",
    "            for iter in range(1, self.iteration+1):\n",
    "                print('new iteration begin ... ')\n",
    "                print('iteration: ', str(iter))\n",
    "                self.logger.info('Epoch: ' + str(iter)+\"\\n\")\n",
    "                all_loss = []\n",
    "                while self.step * self.batch_size < self.dg.records_number:\n",
    "                    # 按批次读取数据\n",
    "                    batch_user, batch_item, batch_session, batch_neg_item, batch_pre_sessions = self.dg.gen_train_batch_data(\n",
    "                        self.batch_size)\n",
    "                    \n",
    "                    _, loss = self.sess.run([self.intention_optimizer, self.intention_loss],\n",
    "                                  feed_dict={self.user_id: batch_user,\n",
    "                                             self.item_id: batch_item,\n",
    "                                             self.current_session: batch_session,\n",
    "                                             self.neg_item_id: batch_neg_item,\n",
    "                                             self.pre_sessions: batch_pre_sessions\n",
    "                                             })\n",
    "                    all_loss.append(loss)\n",
    "                \n",
    "                    self.step += 1\n",
    "\n",
    "                self.loss =  np.mean(all_loss)\n",
    "                self.logger.info('loss' + ' = ' + str(self.loss))\n",
    "\n",
    "                if np.isnan(self.loss):\n",
    "                    self.logger.info('early stop...')\n",
    "                    print(\"early stop...\")\n",
    "                    break\n",
    "\n",
    "                self.step = 0\n",
    "                result = self.evolution( iter )\n",
    "                results.append(result)\n",
    "\n",
    "                record_df = pd.DataFrame(results,columns=['Epoch','Recall@5', 'Recall@10', 'Recall@30', 'Recall@50', 'Recall@65',\n",
    "                                                          'Precision@5', 'Precision@10', 'Precision@30', 'Precision@50', 'Precision@65',\n",
    "                                                          'F1-score@5', 'F1-score@10', 'F1-score@30', 'F1-score@50', 'F1-score@65',\n",
    "                                                          'NDCG@5', 'NDCG@10', 'NDCG@30', 'NDCG@50', 'NDCG@65',\n",
    "                                                          'MAE@5', 'MAE@10', 'MAE@30', 'MAE@50', 'MAE@65', 'Loss'])\n",
    "                if not os.path.exists(\"./output\"):\n",
    "                    os.mkdir(\"./output\")\n",
    "                path = f'./output/{self.path}.csv'\n",
    "                record_df.to_csv(path, index=False)\n",
    "\n",
    "\n",
    "    def precision_k(self, pre_top_k, true_items):\n",
    "        right_pre = 0\n",
    "        user_number = len(pre_top_k)\n",
    "        for i in range(user_number):\n",
    "            if true_items[i] in pre_top_k[i]:\n",
    "                right_pre += 1\n",
    "        return right_pre / user_number\n",
    "\n",
    "    def evolution(self, iter):\n",
    "        pre_top_k = []\n",
    "        predictions = []\n",
    "\n",
    "        for user_id in self.test_users:\n",
    "            batch_user, batch_item, batch_session, batch_pre_session = self.dg.gen_test_batch_data(user_id,\n",
    "                                                                                                   self.batch_size)\n",
    "            top_k_value, top_index, prediction = self.sess.run([self.top_value, self.top_index, self.positive_element_wise],\n",
    "                                                   feed_dict={self.user_id: batch_user,\n",
    "                                                              self.item_id: batch_item,\n",
    "                                                              self.current_session: batch_session,\n",
    "                                                              self.pre_sessions: batch_pre_session})\n",
    "            pre_top_k.append(top_index)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        k_list=[5,10,30,50,65]\n",
    "\n",
    "        f1_score_at_k_eval, recall_at_k_eval, precision_at_k_eval = self.calculate_f1_score_at_k(predictions, self.test_real_items, k_list)\n",
    "        \n",
    "        recall_5_rec = recall_at_k_eval['Recall@5']\n",
    "        recall_10_rec = recall_at_k_eval['Recall@10']\n",
    "        recall_30_rec = recall_at_k_eval['Recall@30']\n",
    "        recall_50_rec = recall_at_k_eval['Recall@50']\n",
    "        recall_65_rec = recall_at_k_eval['Recall@65']\n",
    "        recall_list = [recall_5_rec, recall_10_rec, recall_30_rec, recall_50_rec, recall_65_rec]\n",
    "        \n",
    "        precision_5_rec = precision_at_k_eval['Precision@5']\n",
    "        precision_10_rec = precision_at_k_eval['Precision@10']\n",
    "        precision_30_rec = precision_at_k_eval['Precision@30']\n",
    "        precision_50_rec = precision_at_k_eval['Precision@50']\n",
    "        precision_65_rec = precision_at_k_eval['Precision@65']\n",
    "        precision_list = [precision_5_rec, precision_10_rec, precision_30_rec, precision_50_rec, precision_65_rec]\n",
    "        \n",
    "        f1_5_rec = f1_score_at_k_eval['F1-score@5']\n",
    "        f1_10_rec = f1_score_at_k_eval['F1-score@10']\n",
    "        f1_30_rec = f1_score_at_k_eval['F1-score@30']\n",
    "        f1_50_rec = f1_score_at_k_eval['F1-score@50']\n",
    "        f1_65_rec = f1_score_at_k_eval['F1-score@65']\n",
    "        f1_list = [f1_5_rec, f1_10_rec, f1_30_rec, f1_50_rec, f1_65_rec]\n",
    "\n",
    "        ndcg_at_k_eval = self.calculate_ndcg_at_k(predictions, self.test_real_items, k_list)\n",
    "        ndcg_5_rec = ndcg_at_k_eval['NDCG@5']\n",
    "        ndcg_10_rec = ndcg_at_k_eval['NDCG@10']\n",
    "        ndcg_30_rec = ndcg_at_k_eval['NDCG@30']\n",
    "        ndcg_50_rec = ndcg_at_k_eval['NDCG@50']\n",
    "        ndcg_65_rec = ndcg_at_k_eval['NDCG@65']\n",
    "        ndcg_list = [ndcg_5_rec, ndcg_10_rec, ndcg_30_rec, ndcg_50_rec, ndcg_65_rec]\n",
    "\n",
    "        mae_at_k_eval = self.calculate_mae_at_k(self.test_real_items, k_list)\n",
    "        mae_5_rec = mae_at_k_eval['MAE@5']\n",
    "        mae_10_rec = mae_at_k_eval['MAE@10']\n",
    "        mae_30_rec = mae_at_k_eval['MAE@30']\n",
    "        mae_50_rec = mae_at_k_eval['MAE@50']\n",
    "        mae_65_rec = mae_at_k_eval['MAE@65']\n",
    "        mae_list = [mae_5_rec, mae_10_rec, mae_30_rec, mae_50_rec, mae_65_rec]\n",
    "\n",
    "        result = [iter] + recall_list + precision_list + f1_list + ndcg_list + mae_list + [self.loss]\n",
    "        print(\"calculate_recall_at_k=\", recall_at_k_eval)\n",
    "        print(\"calculate_precision_at_k=\", precision_at_k_eval)\n",
    "        print(\"calculate_f1_score_at_k=\", f1_score_at_k_eval)\n",
    "        print(\"calculate_ndcg_at_k=\", ndcg_at_k_eval)\n",
    "        print(\"calculate_mae_at_k=\", mae_at_k_eval)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def calculate_f1_score_at_k(self, predictions, labels_list, k_list):\n",
    "        # 將預測機率矩陣轉換為 PyTorch 張量。\n",
    "        predictions = torch.from_numpy(np.array(predictions, dtype=np.float32))#.to('cuda')\n",
    "        num_users = len(labels_list)\n",
    "        f1_score_at_k_eval = dict()\n",
    "        recall_at_k_eval = dict()\n",
    "        precision_at_k_eval = dict()\n",
    "        for k in k_list:\n",
    "            f1_score_sum = 0.0\n",
    "            recall_sum = 0.0\n",
    "            precision_sum = 0.0\n",
    "            for i in range(num_users):\n",
    "                    # 將用戶 i 的真實標籤轉換為 PyTorch 張量。\n",
    "                    labels = torch.from_numpy(np.array(labels_list[i], dtype=np.int64))#.to('cuda')\n",
    "                    # 計算用戶 i 在預測機率矩陣中機率最高的 K 個項目的索引。\n",
    "                    top_k_item_labels = torch.topk(predictions[i], k)[1]\n",
    "                    # 計算用戶 i 的真實標籤和預測標籤的交集。 # TP\n",
    "                    true_positives = torch.sum(torch.sum(torch.eq(top_k_item_labels, labels.unsqueeze(1)).to(torch.float32), dim=1)).item()\n",
    "                    # 計算用戶 i 的真實標籤和預測標籤的並集。\n",
    "                    predicted_positives = k # TP+FP\n",
    "                    actual_positives = len(labels) # TP+FN\n",
    "                    if actual_positives == 0:\n",
    "                        precision = 0.0\n",
    "                        recall = 0.0\n",
    "                    else:\n",
    "                        precision = true_positives / predicted_positives\n",
    "                        recall = true_positives / actual_positives\n",
    "                    # 計算 F1-score。\n",
    "                    if precision + recall == 0:\n",
    "                        f1_score = 0.0\n",
    "                    else:\n",
    "                        f1_score = 2 * precision * recall / (precision + recall)\n",
    "                    f1_score_sum += f1_score\n",
    "                    recall_sum += recall\n",
    "                    precision_sum += precision\n",
    "            # 計算平均 F1-score@K 分數。\n",
    "            f1_score_at_k = f1_score_sum / float(num_users)\n",
    "            recall_at_k = recall_sum / float(num_users)\n",
    "            precision_at_k = precision_sum / float(num_users)\n",
    "            key = '{}@{}'.format('F1-score',k)\n",
    "            f1_score_at_k_eval[key]=f1_score_at_k\n",
    "            key = '{}@{}'.format('Recall',k)\n",
    "            recall_at_k_eval[key]=recall_at_k\n",
    "            key = '{}@{}'.format('Precision',k)\n",
    "            precision_at_k_eval[key]=precision_at_k\n",
    "        return f1_score_at_k_eval, recall_at_k_eval, precision_at_k_eval\n",
    "\n",
    "    # NDCG@K\n",
    "    def calculate_ndcg_at_k(self, predictions, labels_list, k_list):\n",
    "        # 將預測機率矩陣轉換為 PyTorch 張量。\n",
    "        predictions = torch.from_numpy(np.array(predictions, dtype=np.float32))\n",
    "        num_users = len(labels_list)\n",
    "        ndcg_at_k_eval = dict()\n",
    "        for k in k_list:\n",
    "            ndcg_sum = 0.0\n",
    "            for i in range(num_users):\n",
    "                # 將用戶 i 的真實標籤轉換為 PyTorch 張量。\n",
    "                labels = torch.from_numpy(np.array(labels_list[i], dtype=np.int64))\n",
    "                # 計算用戶 i 在預測機率矩陣中機率最高的 K 個項目的索引=標籤。\n",
    "                top_k_item_labels = torch.topk(predictions[i], k)[1]\n",
    "                # 計算 DCG@K。\n",
    "                dcg_at_k = torch.sum(torch.div(1.0, torch.log2(torch.arange(k, dtype=torch.float32) + 2)) * (torch.eq(top_k_item_labels, labels.unsqueeze(1)).to(torch.float32) ))\n",
    "                # 計算 IDCG@K。\n",
    "                idcg_at_k = torch.sum(torch.div(1.0, torch.log2(torch.arange(len(labels), dtype=torch.float32) + 2)))\n",
    "            \n",
    "                # 計算 NDCG@K。\n",
    "                ndcg_at_k = dcg_at_k / idcg_at_k\n",
    "                ndcg_sum += ndcg_at_k.item()\n",
    "            # 計算平均 NDCG@K 分數。\n",
    "            ndcg_at_k = ndcg_sum / float(num_users)\n",
    "            key = '{}@{}'.format('NDCG',k)\n",
    "            ndcg_at_k_eval[key]=ndcg_at_k\n",
    "        return ndcg_at_k_eval\n",
    "    \n",
    "    # MAE\n",
    "    def calculate_mae_at_k(self, labels_list, k_list):\n",
    "        num_users = len(labels_list)\n",
    "        mae_eval = dict()\n",
    "        for k in k_list:\n",
    "            mae_sum = 0.0\n",
    "            for i in range(num_users):\n",
    "                labels = torch.from_numpy(np.array(labels_list[i], dtype=np.int64))\n",
    "                mae_sum += abs(k - len(labels))\n",
    "            key = \"{}@{}\".format(\"MAE\", k)\n",
    "            mae_eval[key] = mae_sum / float(num_users)\n",
    "\n",
    "        return mae_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "082216d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init ... \n",
      "init\n",
      "user_number: 12826\n",
      "item_number: 3003\n",
      "building model ... \n",
      "running ... \n",
      "new iteration begin ... \n",
      "iteration:  1\n",
      "calculate_recall_at_k= {'Recall@5': 0.08648893448036753, 'Recall@10': 0.11405744972811097, 'Recall@30': 0.16692517327432685, 'Recall@50': 0.20732729760616558, 'Recall@65': 0.23103587054144217}\n",
      "calculate_precision_at_k= {'Precision@5': 0.11905504444098851, 'Precision@10': 0.08020427257134542, 'Precision@30': 0.04080253651437543, 'Precision@50': 0.030935599563387192, 'Precision@65': 0.02652304813540121}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.08215825509027244, 'F1-score@10': 0.07838876032604486, 'F1-score@30': 0.058092076180445686, 'F1-score@50': 0.04923714887264656, 'F1-score@65': 0.044155104975243116}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.10353190728802912, 'NDCG@10': 0.11976379474995894, 'NDCG@30': 0.14296585504554066, 'NDCG@50': 0.15691648481209536, 'NDCG@65': 0.16411660043715864}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  2\n",
      "calculate_recall_at_k= {'Recall@5': 0.08853429853949905, 'Recall@10': 0.11287462329064382, 'Recall@30': 0.16775551546863157, 'Recall@50': 0.2061486430301869, 'Recall@65': 0.23046748223387237}\n",
      "calculate_precision_at_k= {'Precision@5': 0.11663807890223928, 'Precision@10': 0.0794401995945795, 'Precision@30': 0.04109361193409586, 'Precision@50': 0.030661157024793724, 'Precision@65': 0.026199186748074938}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.0822520711861171, 'F1-score@10': 0.07761347101350025, 'F1-score@30': 0.05847735150566291, 'F1-score@50': 0.04880447429824195, 'F1-score@65': 0.043646485048821654}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.10389223587771121, 'NDCG@10': 0.11913318769056823, 'NDCG@30': 0.14308210711914024, 'NDCG@50': 0.15618848068627728, 'NDCG@65': 0.1633843082328162}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  3\n",
      "calculate_recall_at_k= {'Recall@5': 0.08858649454347903, 'Recall@10': 0.11290939349503062, 'Recall@30': 0.16849849940589176, 'Recall@50': 0.20606900008643325, 'Recall@65': 0.2304006798303261}\n",
      "calculate_precision_at_k= {'Precision@5': 0.11699672540153759, 'Precision@10': 0.07948697957274882, 'Precision@30': 0.04104423306825044, 'Precision@50': 0.030615936379230005, 'Precision@65': 0.026190790341736853}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.08238253799862306, 'F1-score@10': 0.0776357895529413, 'F1-score@30': 0.05843536830881232, 'F1-score@50': 0.04874623514264403, 'F1-score@65': 0.043634143822068955}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.1025090072958681, 'NDCG@10': 0.11766292404690715, 'NDCG@30': 0.1417189675152218, 'NDCG@50': 0.1547029608845799, 'NDCG@65': 0.161926101112171}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  4\n",
      "calculate_recall_at_k= {'Recall@5': 0.08251314026378591, 'Recall@10': 0.10823383470093921, 'Recall@30': 0.1675260485336097, 'Recall@50': 0.20535151027816526, 'Recall@65': 0.22842660570271928}\n",
      "calculate_precision_at_k= {'Precision@5': 0.11160143458600572, 'Precision@10': 0.07631373772026138, 'Precision@30': 0.04100265086543321, 'Precision@50': 0.03056135973803242, 'Precision@65': 0.026156005229764762}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.07782195443318597, 'F1-score@10': 0.07447921902701961, 'F1-score@30': 0.058328318377251574, 'F1-score@50': 0.04865079730878115, 'F1-score@65': 0.043553905148650936}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.09649150439377008, 'NDCG@10': 0.11196279676296206, 'NDCG@30': 0.1375599364980558, 'NDCG@50': 0.15055573249371387, 'NDCG@65': 0.15756637997139328}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  5\n",
      "calculate_recall_at_k= {'Recall@5': 0.0735340801985572, 'Recall@10': 0.09914974490926813, 'Recall@30': 0.16011274303306905, 'Recall@50': 0.19833812725585886, 'Recall@65': 0.21961376060876253}\n",
      "calculate_precision_at_k= {'Precision@5': 0.10115390612818362, 'Precision@10': 0.07022454389521794, 'Precision@30': 0.0391392484016876, 'Precision@50': 0.029447996257602038, 'Precision@65': 0.025226403099476373}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.06997238399684465, 'F1-score@10': 0.06844077766102132, 'F1-score@30': 0.055680201986829575, 'F1-score@50': 0.0468982091440289, 'F1-score@65': 0.04202216447527376}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.08808513018439856, 'NDCG@10': 0.1031989013130226, 'NDCG@30': 0.12934735627621574, 'NDCG@50': 0.14246126379830504, 'NDCG@65': 0.1491177501737823}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  6\n",
      "calculate_recall_at_k= {'Recall@5': 0.06572062671188801, 'Recall@10': 0.09256535188914898, 'Recall@30': 0.15353919400744936, 'Recall@50': 0.19063392612106966, 'Recall@65': 0.21287002701011634}\n",
      "calculate_precision_at_k= {'Precision@5': 0.09259317012319251, 'Precision@10': 0.06597536254483542, 'Precision@30': 0.03769166796611382, 'Precision@50': 0.028362700764073295, 'Precision@65': 0.02437596708608996}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.06333850942396249, 'F1-score@10': 0.06406476990976677, 'F1-score@30': 0.05360342416667232, 'F1-score@50': 0.04515080837362141, 'F1-score@65': 0.04061086207924158}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.07970417009975309, 'NDCG@10': 0.09515428195714616, 'NDCG@30': 0.12137815557157688, 'NDCG@50': 0.1340311450733294, 'NDCG@65': 0.14083772609508458}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  7\n",
      "calculate_recall_at_k= {'Recall@5': 0.06294961874133685, 'Recall@10': 0.08762630101277254, 'Recall@30': 0.14765048881164214, 'Recall@50': 0.18499160590621097, 'Recall@65': 0.20657591051135896}\n",
      "calculate_precision_at_k= {'Precision@5': 0.08793076563231383, 'Precision@10': 0.06321534383284394, 'Precision@30': 0.03635583970061127, 'Precision@50': 0.027525339154842066, 'Precision@65': 0.023670668953690497}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.060407002044145376, 'F1-score@10': 0.061168010171764375, 'F1-score@30': 0.05169302009570474, 'F1-score@50': 0.043836135528987526, 'F1-score@65': 0.039436043758778454}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.07502682879334788, 'NDCG@10': 0.08960109660987194, 'NDCG@30': 0.1153392274702093, 'NDCG@50': 0.1280134838247553, 'NDCG@65': 0.13462006471093826}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  8\n",
      "calculate_recall_at_k= {'Recall@5': 0.06137467724773422, 'Recall@10': 0.08516577237246377, 'Recall@30': 0.14378918631385912, 'Recall@50': 0.18014925869745058, 'Recall@65': 0.20167342487909481}\n",
      "calculate_precision_at_k= {'Precision@5': 0.08456260720412083, 'Precision@10': 0.06129736472790072, 'Precision@30': 0.03549300899215431, 'Precision@50': 0.026804927491034223, 'Precision@65': 0.02312610202833447}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.05841049480086168, 'F1-score@10': 0.05940967721852007, 'F1-score@30': 0.05041971196500958, 'F1-score@50': 0.04269835315654584, 'F1-score@65': 0.03854074639508131}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.07179313322127506, 'NDCG@10': 0.0860682124366094, 'NDCG@30': 0.11123605245910498, 'NDCG@50': 0.12355452211178419, 'NDCG@65': 0.1301726860464178}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  9\n",
      "calculate_recall_at_k= {'Recall@5': 0.05995008276560158, 'Recall@10': 0.08458072553973393, 'Recall@30': 0.14138775877940277, 'Recall@50': 0.17635165307153425, 'Recall@65': 0.19817022027744371}\n",
      "calculate_precision_at_k= {'Precision@5': 0.08202089505691922, 'Precision@10': 0.060291595197259726, 'Precision@30': 0.03468215603721883, 'Precision@50': 0.02619678777483277, 'Precision@65': 0.022721875037486468}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.056784814439760294, 'F1-score@10': 0.0585053010470007, 'F1-score@30': 0.04934435903842397, 'F1-score@50': 0.04173550939778775, 'F1-score@65': 0.03786548255011137}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.06984249952121577, 'NDCG@10': 0.08445572331065593, 'NDCG@30': 0.1088610591277429, 'NDCG@50': 0.1207677806249365, 'NDCG@65': 0.12751113317981502}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_recall_at_k= {'Recall@5': 0.05914181533292707, 'Recall@10': 0.08333316691989678, 'Recall@30': 0.13909503915218935, 'Recall@50': 0.1738466590895636, 'Recall@65': 0.19483424103578223}\n",
      "calculate_precision_at_k= {'Precision@5': 0.08174021518790317, 'Precision@10': 0.05935599563387276, 'Precision@30': 0.03416497738967983, 'Precision@50': 0.025863090597224803, 'Precision@65': 0.022338039319173855}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.05637165856044427, 'F1-score@10': 0.05761499885740795, 'F1-score@30': 0.048611206919816935, 'F1-score@50': 0.041204105903992386, 'F1-score@65': 0.03721540473036242}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.0690555072683041, 'NDCG@10': 0.08327037371513801, 'NDCG@30': 0.10730035043846245, 'NDCG@50': 0.11915367053821392, 'NDCG@65': 0.1255756988855677}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  11\n",
      "calculate_recall_at_k= {'Recall@5': 0.059247423048165195, 'Recall@10': 0.08278509125570535, 'Recall@30': 0.1381274497954314, 'Recall@50': 0.1716681347799161, 'Recall@65': 0.19269381211233452}\n",
      "calculate_precision_at_k= {'Precision@5': 0.0815063152970564, 'Precision@10': 0.058802432558868745, 'Precision@30': 0.03376474868756421, 'Precision@50': 0.025602682052082108, 'Precision@65': 0.02209454353536929}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.05634685761141545, 'F1-score@10': 0.057106098211744984, 'F1-score@30': 0.048063547126154016, 'F1-score@50': 0.04078153038009793, 'F1-score@65': 0.03681263981571101}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.06844822850450699, 'NDCG@10': 0.08222682831880665, 'NDCG@30': 0.10596194419107718, 'NDCG@50': 0.11756331891384346, 'NDCG@65': 0.12394528994349795}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  12\n",
      "calculate_recall_at_k= {'Recall@5': 0.05854938418313802, 'Recall@10': 0.0819009586586992, 'Recall@30': 0.13646630768233178, 'Recall@50': 0.16957309955014913, 'Recall@65': 0.19034498995186316}\n",
      "calculate_precision_at_k= {'Precision@5': 0.08055512240761299, 'Precision@10': 0.05796818961484864, 'Precision@30': 0.033315141119603216, 'Precision@50': 0.02524091688757253, 'Precision@65': 0.021864242104381704}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.055653763750450946, 'F1-score@10': 0.05637429885681601, 'F1-score@30': 0.04743568292553444, 'F1-score@50': 0.04021427352537655, 'F1-score@65': 0.03642824745018001}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.06764037625621043, 'NDCG@10': 0.08128372821088432, 'NDCG@30': 0.10470887022370316, 'NDCG@50': 0.1161387664535031, 'NDCG@65': 0.12254543164397888}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  13\n",
      "calculate_recall_at_k= {'Recall@5': 0.057615255059608864, 'Recall@10': 0.08148034341036865, 'Recall@30': 0.134253517440251, 'Recall@50': 0.1678237959808851, 'Recall@65': 0.1880862603188667}\n",
      "calculate_precision_at_k= {'Precision@5': 0.07938562295337916, 'Precision@10': 0.05758615312646569, 'Precision@30': 0.03295129684495271, 'Precision@50': 0.024971152346796064, 'Precision@65': 0.021662728352267593}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.054758871995249696, 'F1-score@10': 0.056033925461156396, 'F1-score@30': 0.046868215315469725, 'F1-score@50': 0.03978345094287003, 'F1-score@65': 0.036089126299971235}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.06642382142494022, 'NDCG@10': 0.08031694988349652, 'NDCG@30': 0.1031106341202971, 'NDCG@50': 0.11458519026105557, 'NDCG@65': 0.1209130788813889}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  14\n",
      "calculate_recall_at_k= {'Recall@5': 0.05650357663903057, 'Recall@10': 0.08095298305855698, 'Recall@30': 0.13223706953510556, 'Recall@50': 0.16562439675499646, 'Recall@65': 0.18589403283842618}\n",
      "calculate_precision_at_k= {'Precision@5': 0.07820053017308891, 'Precision@10': 0.05713394667082869, 'Precision@30': 0.03254587036748507, 'Precision@50': 0.024740371121160697, 'Precision@65': 0.021431227434660322}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.053869952462232994, 'F1-score@10': 0.05561868172155677, 'F1-score@30': 0.04627650970435172, 'F1-score@50': 0.03940916968560888, 'F1-score@65': 0.03570568501843598}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.06475883451781722, 'NDCG@10': 0.07887783588392235, 'NDCG@30': 0.10113801707076651, 'NDCG@50': 0.1125972931356495, 'NDCG@65': 0.11886652104548429}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n",
      "new iteration begin ... \n",
      "iteration:  15\n",
      "calculate_recall_at_k= {'Recall@5': 0.05483912996250853, 'Recall@10': 0.07996963624158956, 'Recall@30': 0.1306812561760924, 'Recall@50': 0.16372400984420285, 'Recall@65': 0.18372964749412724}\n",
      "calculate_precision_at_k= {'Precision@5': 0.0768439108061778, 'Precision@10': 0.056588180258852996, 'Precision@30': 0.03215343832839769, 'Precision@50': 0.024475284578201074, 'Precision@65': 0.02122371624944755}\n",
      "calculate_f1_score_at_k= {'F1-score@5': 0.052715024554673987, 'F1-score@10': 0.055018458081771554, 'F1-score@30': 0.04574806891804892, 'F1-score@50': 0.038982753737708105, 'F1-score@65': 0.03535421838200522}\n",
      "calculate_ndcg_at_k= {'NDCG@5': 0.06278236021729075, 'NDCG@10': 0.0771724182200956, 'NDCG@30': 0.09918994817382625, 'NDCG@50': 0.11053574417188994, 'NDCG@65': 0.11676000786725065}\n",
      "calculate_mae_at_k= {'MAE@5': 5.3570092000623735, 'MAE@10': 6.437002962731951, 'MAE@30': 22.265476376111025, 'MAE@50': 42.127631373772026, 'MAE@65': 57.12498050834243}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    type = 'Dunnhumby'   # TaFeng, Dunnhumby\n",
    "    global_dimension = 100  # TaFeng: 50, Dunnhumby: 100\n",
    "    epochs = 15  #跑幾個 epochs:  TaFeng: 15 、 Dnnhumby: 15\n",
    "    lr = 0.001    # TaFeng: 0.05, Dunnhumby: 0.05\n",
    "    lamada_u_v = 0.001 # 論文: [0.01、0.001、0.0001]\n",
    "    lamada_a = 1  # 論文: [0,1,10,50]\n",
    "    num = 1 # 紀錄第幾次實驗用，每輪需手動調\n",
    "    model = shan(type, global_dimension, epochs, lr, lamada_u_v, lamada_a, num)\n",
    "    model.build_model()\n",
    "    model.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
