{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735bba3b-6b1b-4f9c-8e02-42748b0caf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from scipy import stats\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a030c834-622e-4edc-aae8-0b22f7fb7a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定\n",
    "epochs = 50\n",
    "batch_size = 32 # Tafeng 64 \\ Dunnhumby 32\n",
    "learning_rate = 0.00001  # Tafeng 0.0001 \\ Dunnhumby 0.00001\n",
    "dataset = \"Dunnhumby\" # 改 \"Tafeng\" or \"Dunnhumby\"\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c598c42-1cf5-4441-b3ff-81ef202577d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義數據集\n",
    "class TaFengDataset(Dataset):\n",
    "    def __init__(self, user_neighbor_data, answer_data):\n",
    "        # 初始化函數，儲存用戶-鄰居數據和答案數據\n",
    "        self.user_neighbor_data = user_neighbor_data\n",
    "        self.answer_data = answer_data\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回數據集中的樣本數量\n",
    "        return len(self.user_neighbor_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 根據索引 idx 返回一個樣本\n",
    "        user_id, user_vector, neighbor_vector = self.user_neighbor_data[idx]\n",
    "        _, _, answer_vector = self.answer_data[idx]\n",
    "\n",
    "        # 返回用戶向量、鄰居向量和答案向量，轉換為適當的 tensor 類型\n",
    "        return torch.tensor(user_vector, dtype=torch.float32), \\\n",
    "               torch.tensor(neighbor_vector, dtype=torch.float32), \\\n",
    "               answer_vector.clone().detach().to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14dceee3-90d2-4ce6-b761-52f9bb73841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入數據\n",
    "with gzip.open(f\"data/preprocessed_data/{dataset}_training_user_and_neighbor_set.gz\", \"rb\") as fp:\n",
    "    TaFeng_training_user_and_neighbor_set = pickle.load(fp)\n",
    "\n",
    "with gzip.open(f\"data/preprocessed_data/{dataset}_training_answer.gz\", \"rb\") as fp:\n",
    "    TaFeng_training_answer = pickle.load(fp)\n",
    "\n",
    "with gzip.open(f\"data/preprocessed_data/{dataset}_validation_user_and_neighbor_set.gz\", \"rb\") as fp:\n",
    "    TaFeng_validation_user_and_neighbor_set = pickle.load(fp)\n",
    "\n",
    "with gzip.open(f\"data/preprocessed_data/{dataset}_validation_answer.gz\", \"rb\") as fp:\n",
    "    TaFeng_validation_answer = pickle.load(fp)\n",
    "\n",
    "with gzip.open(f\"data/preprocessed_data/{dataset}_test_user_and_neighbor_set.gz\", \"rb\") as fp:\n",
    "    TaFeng_test_user_and_neighbor_set = pickle.load(fp)\n",
    "\n",
    "with gzip.open(f\"data/preprocessed_data/{dataset}_test_answer.gz\", \"rb\") as fp:\n",
    "    TaFeng_test_answer = pickle.load(fp)\n",
    "\n",
    "# 設備配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 設置數據加載器\n",
    "training_dataset = TaFengDataset(TaFeng_training_user_and_neighbor_set, TaFeng_training_answer)\n",
    "training_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_dataset = TaFengDataset(TaFeng_validation_user_and_neighbor_set, TaFeng_validation_answer)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = TaFengDataset(TaFeng_test_user_and_neighbor_set, TaFeng_test_answer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4c8ee1f-80c6-4461-a5df-004b363ac423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義模型\n",
    "class AttentionMechanism(nn.Module):\n",
    "    def __init__(self, vector_size):\n",
    "        super(AttentionMechanism, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.7))\n",
    "\n",
    "    def forward(self, user_vector, neighbor_vector):\n",
    "        \n",
    "        weighted_neighbor_vector = self.alpha * neighbor_vector\n",
    "        weighted_user_vector = (1 - self.alpha) * user_vector\n",
    "        Ans_1 = weighted_user_vector + weighted_neighbor_vector\n",
    "        \n",
    "        return Ans_1\n",
    "\n",
    "# 初始化模型、損失函數和優化器\n",
    "vector_size = 12087\n",
    "model = AttentionMechanism(vector_size).to(device)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbacbdbf-5061-4287-8a95-7512531a4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topk_metrics(predictions, targets, k):\n",
    "    # 将模型输出转换为 top-k 二值向量\n",
    "    _, top_indices = torch.topk(predictions, k, dim=1)\n",
    "    topk_binary_vector = torch.zeros_like(predictions)\n",
    "    topk_binary_vector.scatter_(1, top_indices, 1)\n",
    "\n",
    "    # 计算 true positives, false positives, false negatives\n",
    "    true_positives = torch.sum(topk_binary_vector * targets, dim=1)\n",
    "    false_positives = torch.sum(topk_binary_vector * (1 - targets), dim=1)\n",
    "    false_negatives = torch.sum((1 - topk_binary_vector) * targets, dim=1)\n",
    "\n",
    "    # 计算指标\n",
    "    recall = torch.mean(true_positives / (true_positives + false_negatives))\n",
    "    precision = torch.mean(true_positives / (true_positives + false_positives))\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    # 计算 Hit Ratio (HR)\n",
    "    hr = torch.mean((true_positives > 0).float())\n",
    "\n",
    "    return recall.item(), precision.item(), f1.item(), hr.item()\n",
    "    \n",
    "def ndcg_score(predictions, targets, k):\n",
    "\n",
    "    # 获取 top-k 预测项的索引\n",
    "    _, top_indices = torch.topk(predictions, k, dim=1)\n",
    "    \n",
    "    # 生成 DCG 分数\n",
    "    dcg = 0.0\n",
    "    for i in range(1, k + 1):\n",
    "        dcg += ((2 ** targets.gather(1, top_indices[:, i - 1].view(-1, 1)) - 1) / torch.log2(torch.tensor(i + 1).float())).squeeze()\n",
    "\n",
    "    # 生成理想的 DCG 分数 (IDCG)\n",
    "    _, ideal_indices = torch.topk(targets, k, dim=1)\n",
    "    idcg = 0.0\n",
    "    for i in range(1, k + 1):\n",
    "        idcg += ((2 ** targets.gather(1, ideal_indices[:, i - 1].view(-1, 1)) - 1) / torch.log2(torch.tensor(i + 1).float())).squeeze()\n",
    "\n",
    "    # 处理 IDCG 为 0 的情况，防止除以零\n",
    "    idcg[idcg == 0] = 1.0\n",
    "\n",
    "    # 计算 NDCG\n",
    "    ndcg = torch.mean(dcg / idcg)\n",
    "\n",
    "    return ndcg.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a41ed6c-2b40-4789-b327-5b31d5347018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(loader, model, k, device):\n",
    "    model.eval()  # 切换到评估模式\n",
    "    total_recall, total_precision, total_f1, total_hr, total_ndcg = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for user_vector, neighbor_vector, answer_vector in loader:\n",
    "            user_vector, neighbor_vector, answer_vector = user_vector.to(device), neighbor_vector.to(device), answer_vector.to(device)\n",
    "            \n",
    "            predictions = model(user_vector, neighbor_vector)\n",
    "\n",
    "            recall, precision, f1, hr = calculate_topk_metrics(predictions, answer_vector, k)\n",
    "            ndcg = ndcg_score(predictions, answer_vector, k)\n",
    "            \n",
    "            total_recall += recall\n",
    "            total_precision += precision\n",
    "            total_f1 += f1\n",
    "            total_hr += hr\n",
    "            total_ndcg += ndcg\n",
    "\n",
    "    num_samples = len(loader)\n",
    "    metrics = {\n",
    "        'recall': total_recall / num_samples,\n",
    "        'precision': total_precision / num_samples,\n",
    "        'f1': total_f1 / num_samples,\n",
    "        'hr': total_hr / num_samples,\n",
    "        'ndcg': total_ndcg / num_samples\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eec3b89d-4191-433c-989e-e3244e0d7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化早停参数\n",
    "best_f1 = 0  # 记录最佳F1 score\n",
    "epochs_no_improve = 0  # 记录没有改进的epoch数量\n",
    "patience = 2 # 设置耐心值，即在停止训练之前可以容忍多少个没有改进的epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ad5033a-174d-4711-b467-723b31d87632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 289/289 [00:01<00:00, 243.53it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Validation Recall: 0.2750 | Precision: 0.1945 | F1 Score: 0.2247 | NDCG: 0.3114 | HR: 0.7112\n",
      "Epoch 1: F1 score improved to 0.22473700073632327. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 289/289 [00:01<00:00, 260.08it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Validation Recall: 0.2746 | Precision: 0.1944 | F1 Score: 0.2245 | NDCG: 0.3111 | HR: 0.7102\n",
      "Epoch 2: F1 score did not improve. (1 epochs with no improvement)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 289/289 [00:01<00:00, 253.13it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Validation Recall: 0.2747 | Precision: 0.1946 | F1 Score: 0.2247 | NDCG: 0.3110 | HR: 0.7102\n",
      "Epoch 3: F1 score did not improve. (2 epochs with no improvement)\n",
      "Early stopping triggered after 3 epochs.\n",
      "Test Recall: 0.2712 | Precision: 0.1949 | F1 Score: 0.2245 | NDCG: 0.3101 | HR: 0.7167\n"
     ]
    }
   ],
   "source": [
    "# 训练循环\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # 切换到训练模式\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # 使用tqdm创建进度条\n",
    "    progress_bar = tqdm(enumerate(training_loader), total=len(training_loader), desc=f\"Epoch {epoch+1}\")\n",
    "    for batch_idx, (user_vector, neighbor_vector, answer_vector) in progress_bar:\n",
    "        user_vector, neighbor_vector, answer_vector = user_vector.to(device), neighbor_vector.to(device), answer_vector.to(device)\n",
    "        \n",
    "        predictions = model(user_vector, neighbor_vector)\n",
    "        loss = loss_function(predictions, answer_vector)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        # 在进度条中更新后缀，显示当前批次的平均损失\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(training_loader)\n",
    "    # 进度条完成后打印平均损失\n",
    "    progress_bar.set_postfix({'avg_loss': avg_loss})\n",
    "\n",
    "    # 在每个epoch结束后使用验证集评估模型\n",
    "    validation_metrics = evaluate_model(validation_loader, model, k, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Validation Recall: {validation_metrics['recall']:.4f} | \"\n",
    "      f\"Precision: {validation_metrics['precision']:.4f} | F1 Score: {validation_metrics['f1']:.4f} | \"\n",
    "      f\"NDCG: {validation_metrics['ndcg']:.4f} | HR: {validation_metrics['hr']:.4f}\")\n",
    "    \n",
    "    # 检查F1分数是否有改进\n",
    "    if validation_metrics['f1'] > best_f1:\n",
    "        best_f1 = validation_metrics['f1']\n",
    "        epochs_no_improve = 0\n",
    "        # 保存模型\n",
    "        torch.save(model.state_dict(), 'model_best.pth')\n",
    "        print(f\"Epoch {epoch+1}: F1 score improved to {best_f1}. Model saved.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"Epoch {epoch+1}: F1 score did not improve. ({epochs_no_improve} epochs with no improvement)\")\n",
    "\n",
    "    # 检查是否达到了早停条件\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f'Early stopping triggered after {epoch + 1} epochs.')\n",
    "        break\n",
    "            \n",
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load('model_best.pth'))\n",
    "\n",
    "# 使用测试集进行最终评估\n",
    "test_metrics = evaluate_model(test_loader, model, k, device)\n",
    "print(f\"Test Recall: {test_metrics['recall']:.4f} | Precision: {test_metrics['precision']:.4f} | \"\n",
    "      f\"F1 Score: {test_metrics['f1']:.4f} | NDCG: {test_metrics['ndcg']:.4f} | HR: {test_metrics['hr']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pifta",
   "language": "python",
   "name": "pifta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
